{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f2642e-3209-45cb-9949-33a90731980e",
   "metadata": {},
   "source": [
    "Pour r√©ussir ce projet, il faut d'abord que la logique du code fonctionne sur machine avant d'essayer de l'envoyer dans le Cloud √† partir de Docker.\n",
    "Voici ce que le code python fait : \n",
    "\n",
    "Il d√©tecte une vid√©o dans un dossier input.\n",
    "Il transforme cette vid√©o (r√©duction de taille - \"Downscale\").\n",
    "Il analyse la vid√©o (simule la d√©tection de langue et d'animaux).\n",
    "Il emballe le tout (cr√©e un fichier JSON avec les infos).\n",
    "\n",
    "Pr√©r√©quis \n",
    "Installer ffmpeg sur le lien suivant : https://www.gyan.dev/ffmpeg/builds/ et mettre le fichier .exe dans le dossier jupyter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75142f7c-b1dc-418f-9bba-85e214e0e15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: future in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from ffmpeg-python) (0.18.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e4c55db-70f3-426c-b471-b2deca244289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: pydub in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (3.14.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (10.2.0)\n",
      "Requirement already satisfied: gTTS in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (2.5.4)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (2.2.6)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (0.21.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from gTTS) (2.31.0)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from gTTS) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gTTS) (0.4.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTS) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy pydub SpeechRecognition Pillow gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38c413ca-045c-4f5e-ad95-9acc402d744b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (2.2.6)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (0.21.0)\n",
      "Requirement already satisfied: pillow<12.0,>=9.2.0 in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from moviepy) (10.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from proglog<=1.0.0->moviepy) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from tqdm->proglog<=1.0.0->moviepy) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d69b5f0-8e32-472c-b46d-0ff67baf492d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (3.14.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b553155-7f87-4802-a24b-e535ed307315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in c:\\users\\noupoue merveille\\anaconda3\\lib\\site-packages (0.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f197bab-9572-47fd-b787-da3292b1379e",
   "metadata": {},
   "source": [
    "Pour diviser l'audio en fragments de 5 secondes et permettre √† Speech recognition de transcrire fid√®le. Car utilis√©e seule ne transcit que les 5 premi√®res secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc20a7b-0916-42c8-96c6-f4b693b781ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import ffmpeg \n",
    "from PIL import Image\n",
    "import speech_recognition as sr \n",
    "from pydub import AudioSegment # Nouveau module utilis√© pour diviser l'audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b78a505c-26b8-4114-ae0d-a20a09c901b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION DES DOSSIERS ---\n",
    "INPUT_FOLDER = \"videos_input\"\n",
    "OUTPUT_FOLDER = \"videos_output\"\n",
    "TEMP_AUDIO_FILE = \"temp_audio.wav\"\n",
    "\n",
    "# Cr√©ation automatique des dossiers si absents\n",
    "os.makedirs(INPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a11dfda-3ab6-4b23-8b2f-db0f592469ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FONCTIONS UTILITAIRES (Extraction Audio) ---\n",
    "\n",
    "def extract_audio(video_path):\n",
    "    \"\"\"\n",
    "    Extrait la piste audio de la vid√©o vers un fichier WAV temporaire \n",
    "    \"\"\"\n",
    "    print(\"+++ Extraction de l'audio (via ffmpeg)...\")\n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_path)\n",
    "            .output(\n",
    "                TEMP_AUDIO_FILE, \n",
    "                format='wav', \n",
    "                acodec='pcm_s16le', \n",
    "                loglevel=\"quiet\"\n",
    "            )\n",
    "            .run(overwrite_output=True)\n",
    "        )\n",
    "        print(f\"‚úÖ Audio extrait temporairement dans {TEMP_AUDIO_FILE}.\")\n",
    "        return TEMP_AUDIO_FILE\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de l'extraction audio: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f04ca14-68f7-4bb8-a0f6-72c8a2586f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FONCTIONS SIMULANT LES \"PODS\" DU PROJET ---\n",
    "\n",
    "def pod_downscale(input_path, output_path):\n",
    "    \"\"\"\n",
    "    R√©duit la r√©solution et compresse la vid√©o.\n",
    "    \"\"\"\n",
    "    print(f\"üé¨ Traitement de {input_path}...\")\n",
    "    try:\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(input_path)\n",
    "            .output(\n",
    "                output_path, \n",
    "                vf='scale=640:-1', \n",
    "                vcodec='libx264',   \n",
    "                crf=28,             \n",
    "                loglevel=\"quiet\"\n",
    "            )\n",
    "            .run(overwrite_output=True)\n",
    "        )\n",
    "        print(f\"‚úÖ Succ√®s ! Vid√©o r√©duite et compress√©e cr√©√©e : {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la conversion : {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def pod_lang_ident(audio_path):\n",
    "    \"\"\"\n",
    "    D√©tecte la langue sur un extrait audio.\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    langue_code = \"unk\"\n",
    "    \n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            # N'√©coute que les 5 premi√®res secondes pour la d√©tection rapide de la langue\n",
    "            audio = r.record(source, duration=5) \n",
    "        \n",
    "        # Tentative de d√©tection\n",
    "        try:\n",
    "            r.recognize_google(audio, language=\"fr-FR\", show_all=False)\n",
    "            langue_code = \"fr\"\n",
    "        except sr.UnknownValueError:\n",
    "             try:\n",
    "                r.recognize_google(audio, language=\"en-US\", show_all=False)\n",
    "                langue_code = \"en\"\n",
    "             except:\n",
    "                langue_code = \"unk\"\n",
    "\n",
    "        langues = {\"fr\": \"Fran√ßais üá´üá∑\", \"en\": \"Anglais üá¨üáß\", \"unk\": \"Inconnue ‚ùì\"}\n",
    "        print(f\"+++ Analyse de la langue sur extrait... R√©sultat: {langues[langue_code]}\")\n",
    "        \n",
    "        return langue_code\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la d√©tection de langue: {e}\")\n",
    "        return \"unk\"\n",
    "\n",
    "\n",
    "def pod_transcribe_full(audio_path, langue_code):\n",
    "    \"\"\"\n",
    "    Transcrit l'int√©gralit√© du fichier audio en divisant l'audio en morceaux (chunks).\n",
    "    \"\"\"\n",
    "    if langue_code == 'unk':\n",
    "        return \"\" # Ne transcrit pas si la langue est inconnue\n",
    "        \n",
    "    print(f\"+++ Transcription compl√®te en cours (langue: {langue_code})...\")\n",
    "    r = sr.Recognizer()\n",
    "    full_transcription = []\n",
    "    \n",
    "    # D√©finir la langue pour l'API Google\n",
    "    api_lang = \"fr-FR\" if langue_code == \"fr\" else \"en-US\"\n",
    "    \n",
    "    # Division de l'audio en morceaux de 30 secondes\n",
    "    chunk_size_ms = 30000 \n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    \n",
    "    # It√©ration sur chaque morceau\n",
    "    for i, start_ms in enumerate(range(0, len(audio), chunk_size_ms)):\n",
    "        end_ms = start_ms + chunk_size_ms\n",
    "        chunk = audio[start_ms:end_ms]\n",
    "        \n",
    "        # Sauvegarde temporaire du morceau\n",
    "        chunk.export(\"temp_chunk.wav\", format=\"wav\")\n",
    "        \n",
    "        # Reconnaissance vocale sur le morceau\n",
    "        with sr.AudioFile(\"temp_chunk.wav\") as source:\n",
    "            audio_data = r.record(source)\n",
    "            \n",
    "            try:\n",
    "                text = r.recognize_google(audio_data, language=api_lang, show_all=False)\n",
    "                full_transcription.append(text)\n",
    "                print(f\"   [Chunk {i+1}] Transcrit: '{text[:30]}...'\")\n",
    "            except sr.UnknownValueError:\n",
    "                # print(f\"   [Chunk {i+1}] Parole non reconnue.\")\n",
    "                pass\n",
    "            except sr.RequestError as e:\n",
    "                print(f\"‚ùå Erreur de l'API Google sur le chunk {i+1}: {e}\")\n",
    "                return \"Erreur API lors de la transcription compl√®te.\"\n",
    "    \n",
    "    # Nettoyage du fichier temporaire du chunk\n",
    "    if os.path.exists(\"temp_chunk.wav\"): os.remove(\"temp_chunk.wav\")\n",
    "    \n",
    "    final_text = \" \".join(full_transcription)\n",
    "    print(\"‚úÖ Transcription compl√®te termin√©e.\")\n",
    "    \n",
    "    return final_text\n",
    "\n",
    "\n",
    "def pod_animal_detect(video_path):\n",
    "    \"\"\"\n",
    "    Analyse une image pour une d√©tection simple (bas√©e sur le contenu visuel).\n",
    "    \"\"\"\n",
    "    temp_frame = \"temp_frame.jpg\"\n",
    "    try:\n",
    "        # 1. Extraction d'une image cl√© √† 1 seconde\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_path)\n",
    "            .filter('select', 'gte(n, 30)') \n",
    "            .output(temp_frame, vframes=1, loglevel=\"quiet\")\n",
    "            .run(overwrite_output=True)\n",
    "        )\n",
    "    except Exception:\n",
    "        return \"Non ‚ùå\"\n",
    "\n",
    "    # 2. Analyse de l'image \n",
    "    try:\n",
    "        img = Image.open(temp_frame)\n",
    "        pixels = img.getdata()\n",
    "        \n",
    "        green_pixels = sum(1 for r, g, b in pixels if g > 100 and g > r + 30 and g > b + 30)\n",
    "        \n",
    "        if green_pixels / (img.width * img.height) > 0.001:\n",
    "             animal_detected = \"Oui \" \n",
    "        else:\n",
    "             animal_detected = \"Non \"\n",
    "        \n",
    "        os.remove(temp_frame)\n",
    "    except Exception:\n",
    "        animal_detected = \"Non \"\n",
    "\n",
    "    print(f\"+++ Analyse d'image... R√©sultat: {animal_detected}\")\n",
    "    return animal_detected\n",
    "\n",
    "\n",
    "def pod_subtitle(base_filename, output_folder, langue_code, transcription):\n",
    "    \"\"\"\n",
    "    G√©n√®re un fichier de sous-titres .srt bas√© sur la transcription compl√®te.\n",
    "    \"\"\"\n",
    "    subtitle_filename = f\"{base_filename}.{langue_code}.srt\"\n",
    "    output_path = os.path.join(output_folder, subtitle_filename)\n",
    "    \n",
    "    # On utilise la transcription pour le contenu du sous-titre\n",
    "    if transcription:\n",
    "        texte = transcription\n",
    "    else:\n",
    "        texte = \"Pas de transcription vocale d√©tect√©e.\"\n",
    "        \n",
    "    # G√©n√©ration du format SubRip (.srt) - Affichage des 100 premiers caract√®res\n",
    "    srt_content = f\"1\\n00:00:01,000 --> 00:00:05,000\\n{texte[:100]}...\" \n",
    "    \n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(srt_content)\n",
    "        \n",
    "        print(f\"+++ Fichier de sous-titres g√©n√©r√© : {subtitle_filename}\")\n",
    "        return subtitle_filename\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de la cr√©ation du fichier SRT : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_metadata(filename, langue, animal_result, subtitle_file, full_transcription, path_json):\n",
    "    \"\"\"\n",
    "    G√©n√®re les m√©tadonn√©es et inclut la transcription compl√®te.\n",
    "    \"\"\"\n",
    "    animal_status = animal_result.split()[0]\n",
    "    \n",
    "    metadata = {\n",
    "        \"video_name_original\": filename,\n",
    "        \"video_name_processed\": f\"processed_{filename}\",\n",
    "        \"subtitle_file\": subtitle_file if subtitle_file else \"None\",\n",
    "        \"language_code\": langue,\n",
    "        # On stocke ici la transcription compl√®te\n",
    "        \"full_transcription\": full_transcription, \n",
    "        \"animal_detected\": animal_status,\n",
    "        \"processing_time\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"status\": \"processed_locally\"\n",
    "    }\n",
    "    \n",
    "    with open(path_json, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "        \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff410fa-cb9d-4583-8a8d-579b99f11d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©marrage du Pipeline Vid√©o Local\n",
      "\n",
      "--- Traitement de : Lecon de vie.mp4 ---\n",
      "üé¨ Traitement de videos_input\\Lecon de vie.mp4...\n",
      "‚úÖ Succ√®s ! Vid√©o r√©duite et compress√©e cr√©√©e : videos_output\\processed_Lecon de vie.mp4\n",
      "+++ Extraction de l'audio (via ffmpeg)...\n",
      "‚úÖ Audio extrait temporairement dans temp_audio.wav.\n",
      "+++ [LangIdent] Analyse de la langue sur extrait... R√©sultat: Fran√ßais üá´üá∑\n",
      "+++ Transcription compl√®te en cours (langue: fr)...\n",
      "   [Chunk 1] Transcrit: 'bonjour est-ce que je peux com...'\n",
      "   [Chunk 2] Transcrit: 'bonjour je viens pour l'entret...'\n",
      "   [Chunk 3] Transcrit: 'je vous en prie asseyez-vous v...'\n",
      "   [Chunk 4] Transcrit: 'montre-moi de gravir les √©chel...'\n",
      "   [Chunk 5] Transcrit: 'ce matin j'√©tais l√† au bar et ...'\n",
      "   [Chunk 6] Transcrit: 'vous devez des excuses mais je...'\n",
      "   [Chunk 7] Transcrit: 'd'empathie et de gentillesse q...'\n",
      "   [Chunk 8] Transcrit: 'comp√©tence vous n'aurez pas le...'\n",
      "   [Chunk 9] Transcrit: 'dis ok vous ne vous attendiez ...'\n",
      "   [Chunk 10] Transcrit: 'excusez-moi madame vous avez o...'\n",
      "   [Chunk 11] Transcrit: 'et c'est ce que j'ai fait avec...'\n",
      "   [Chunk 12] Transcrit: 'je suis comptable enchant√© √âlo...'\n",
      "   [Chunk 13] Transcrit: 'et vous ramener les croissants...'\n",
      "‚úÖ Transcription compl√®te termin√©e.\n",
      "+++ Analyse d'image... R√©sultat: Non \n",
      "üí¨ [Subtitle] Fichier de sous-titres g√©n√©r√© : Lecon de vie.fr.srt\n",
      "\n",
      " Affichage des m√©tadonn√©es :\n",
      "------------------------------------------------------------------\n",
      "| video_name_original       : Lecon de vie.mp4          |\n",
      "\n",
      "| video_name_processed      : processed_Lecon de vie.mp4 |\n",
      "\n",
      "| subtitle_file             : Lecon de vie.fr.srt       |\n",
      "\n",
      "| language_code             : fr                        |\n",
      "\n",
      "| full_transcription        : bonjour est-ce que je peux comprendre j'√©tais en train de le prendre ce croissant j'√©tais peut-√™tre ... |\n",
      "\n",
      "| animal_detected           : Non                       |\n",
      "\n",
      "| processing_time           : 2025-11-27 18:14:41       |\n",
      "\n",
      "| status                    : processed_locally         |\n",
      "\n",
      "------------------------------------------------------------------\n",
      " Fichier JSON enregistr√© : videos_output\\Lecon de vie.mp4.json\n",
      " Cycle termin√© pour cette vid√©o.\n"
     ]
    }
   ],
   "source": [
    "# --- LE CHEF D'ORCHESTRE (MAIN) ---\n",
    "\n",
    "def main_pipeline():\n",
    "    print(\"üöÄ D√©marrage du Pipeline Vid√©o Local\")\n",
    "    \n",
    "    fichiers = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
    "    \n",
    "    if not fichiers:\n",
    "        print(f\" Aucune vid√©o trouv√©e dans le dossier '{INPUT_FOLDER}'.\")\n",
    "        print(\" Veuillez y d√©poser une vid√©o (ex: test.mp4) et relancer.\")\n",
    "        return\n",
    "\n",
    "    for video_file in fichiers:\n",
    "        path_entree = os.path.join(INPUT_FOLDER, video_file)\n",
    "        path_sortie = os.path.join(OUTPUT_FOLDER, f\"processed_{video_file}\")\n",
    "        path_json = os.path.join(OUTPUT_FOLDER, f\"{video_file}.json\")\n",
    "        base_filename = os.path.splitext(video_file)[0] \n",
    "\n",
    "        # ETAPE 1 : DOWNSCALE\n",
    "        success = pod_downscale(path_entree, path_sortie)\n",
    "        \n",
    "        if success:\n",
    "            \n",
    "            # Pr√©pare l'audio\n",
    "            audio_path = extract_audio(path_entree)\n",
    "            \n",
    "            # ETAPE 2 : LANCEMENT DES ANALYSES\n",
    "            full_transcription = \"\"\n",
    "            if audio_path:\n",
    "                # 2a. D√©tection de langue rapide\n",
    "                langue_result = pod_lang_ident(audio_path)\n",
    "                \n",
    "                # 2b. Transcription compl√®te si la langue est connue\n",
    "                if langue_result != \"unk\":\n",
    "                    full_transcription = pod_transcribe_full(audio_path, langue_result)\n",
    "                \n",
    "                # Nettoyage du fichier audio temporaire\n",
    "                if os.path.exists(TEMP_AUDIO_FILE): os.remove(TEMP_AUDIO_FILE)\n",
    "            else:\n",
    "                langue_result = \"unk\"\n",
    "                \n",
    "            # D√©tection d'animal\n",
    "            animal_result = pod_animal_detect(path_entree)\n",
    "            \n",
    "            # ETAPE 3 : SOUS-TITRES (bas√©s sur la transcription)\n",
    "            subtitle_file = pod_subtitle(base_filename, OUTPUT_FOLDER, langue_result, full_transcription)\n",
    "\n",
    "            # ETAPE 4 : METADONNEES & STOCKAGE (inclut la transcription compl√®te)\n",
    "            metadata_dict = generate_metadata(video_file, langue_result, animal_result, subtitle_file, full_transcription, path_json)\n",
    "\n",
    "            # AFFICHAGE DES METADONN√âES FINALES\n",
    "            print(\"\\n Affichage des m√©tadonn√©es :\")\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            for key, value in metadata_dict.items():\n",
    "                # Affiche seulement un extrait de la transcription pour la console\n",
    "                display_value = str(value)\n",
    "                if key == \"full_transcription\" and len(display_value) > 100:\n",
    "                    display_value = display_value[:100] + \"...\"\n",
    "                    \n",
    "                print(f\"| {key.ljust(25)} : {display_value.ljust(25)} |\\n\")\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            \n",
    "            print(f\" Fichier JSON enregistr√© : {path_json}\")\n",
    "            print(\" Cycle termin√© pour cette vid√©o.\")\n",
    "\n",
    "# --- LANCEMENT ---\n",
    "main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc862fa8-af42-4f13-9413-e52407813606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498ca3e-3904-408f-894b-6365092a81d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
